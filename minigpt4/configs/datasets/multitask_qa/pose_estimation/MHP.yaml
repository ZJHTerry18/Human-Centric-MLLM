datasets:
  MHP_pose_qa: # name of the dataset builder
    data_type: images # [images|videos|features]
    vis_processor: 
      common:
        data_cfg:
          image_size: [448, 448]
          mean: [0.48145466, 0.4578275, 0.40821073]
          std: [0.26862954, 0.26130258, 0.27577711]
          all_keypoint_dict: {0: 'right_ankle ', 1: 'right_knee', 2: 'right_hip', 3: 'left_hip', 4: 'left_knee', 5: 'left_ankle', 6: 'pelvis', 7: 'thorax', 8: 'upper_neck', 9: 'head_top', 10: 'right_wrist', 11: 'right_elbow', 12: 'right_shoulder', 13: 'left_shoulder', 14: 'left_elbow', 15: 'left_wrist'}
          flip_pairs: [[0,5], [1,4], [2,3], [10,15], [11,14], [12,13]]
      train:
        name: "blip2_image_pose_qa_train"
        data_cfg: 
          simp_aug: True
      eval:
        name: "blip2_image_pose_qa_eval"
        data_cfg: {}
                  
    text_processor:
        train:
          name: "blip2_text_pose_qa_train"
        eval:
          name: "blip2_text_pose_qa_eval"

    build_info:
      image_path: /data/datasets/dataset_pose/MHP
      ann_path:
        train: /data/datasets/dataset_pose/MHP/MHP_pose_train_bbox.jsonl
      template_path: minigpt4/configs/datasets/multitask_qa/pose_estimation/qa_template.json
      


