datasets:
  human36m_pose_qa:
    data_type: images # [images|videos|features]
    vis_processor: 
      common:
        data_cfg:
          image_size: [448, 448]
          mean: [0.48145466, 0.4578275, 0.40821073]
          std: [0.26862954, 0.26130258, 0.27577711]
          # all_keypoint_dict: {0: 'hip', 1: 'left_hip', 2: 'left_knee', 3: 'left_foot', 4: 'right_hip', 5: 'right_knee', 6: 'right_foot', 7: 'spine', 8: 'thorax', 9: 'neck', 10: 'head', 11: 'left_shoulder', 12: 'left_elbow', 13: 'left_wrist', 14: 'right_shoulder', 15: 'right_elbow', 16: 'right_wrist'}
          all_keypoint_dict: {0: 'nose', 1: 'head top', 2: 'neck', 3: 'left eye', 4: 'right eye', 5: 'left ear', 6: 'right ear', 7: 'left shoulder', 8: 'right shoulder', 9: 'left elbow', 10: 'right elbow', 11: 'left wrist', 12: 'right wrist', 13: 'left hip', 14: 'right hip', 15: 'left knee', 16: 'right knee', 17: 'left ankle', 18: 'right ankle'}
          flip_pairs: [[3,4], [5,6], [7,8], [9,10], [11,12], [13,14], [15,16], [17,18]]
      train:
        name: "blip2_image_pose_qa_train"
        data_cfg: 
          # 'dataset_name': 'coco',
          simp_aug: True
          # 'use_udp': True,
      eval:
        name: "blip2_image_pose_qa_eval"
        data_cfg: 
          image_size: [448, 448]
          # all_keypoint_dict: {0: 'hip', 1: 'left_hip', 2: 'left_knee', 3: 'left_foot', 4: 'right_hip', 5: 'right_knee', 6: 'right_foot', 7: 'spine', 8: 'thorax', 9: 'neck', 10: 'head', 11: 'left_shoulder', 12: 'left_elbow', 13: 'left_wrist', 14: 'right_shoulder', 15: 'right_elbow', 16: 'right_wrist'}
          all_keypoint_dict: {0: 'nose', 1: 'head top', 2: 'neck', 3: 'left eye', 4: 'right eye', 5: 'left ear', 6: 'right ear', 7: 'left shoulder', 8: 'right shoulder', 9: 'left elbow', 10: 'right elbow', 11: 'left wrist', 12: 'right wrist', 13: 'left hip', 14: 'right hip', 15: 'left knee', 16: 'right knee', 17: 'left ankle', 18: 'right ankle'}
          skeleton : [[0,1], [0,4], [1,2], [2,3], [4,5], [5,6], [7,0], [7,8], [8,9], [9,10], [8,11], [8,14], [11,12], [12,13], [14,15], [15,16] ]
          sigmas : [0.026, 0.025, 0.025, 0.035, 0.035, 0.079, 0.079, 0.072,0.072, 0.062,0.062, 0.107, 0.107, 0.087, 0.087, 0.089,0.089]
          # sigmas: [
          #         1.0, 0.062, 0.062, 1.0, 1.0, 1.0, 1.0, 0.107, 0.087, 0.107, 0.089, 0.087, 0.089, 0.025, 0.035, 0.025, 0.079, 0.035, 0.079
          #         ]
          use_area: False

    text_processor:
        train:
          name: "blip2_text_pose_qa_train"
        eval:
          name: "blip2_text_pose_qa_eval"

    build_info:
      image_path: /data/datasets/dataset_pose/human3.6m
      ann_path:
        train: /data/datasets/dataset_pose/human3.6m/h36m_pose_train_bbox.jsonl
      template_path: minigpt4/configs/datasets/multitask_qa/pose_estimation/qa_template.json
