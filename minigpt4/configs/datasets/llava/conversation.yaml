datasets:
  llava_conversation:
    data_type: images
    vis_processor:
      train:
        name: "blip2_image_train"
        image_size: 448
    text_processor:
      train:
        name: "blip_caption"
    build_info:
      image_path: /data/datasets/dataset_ref/coco2014/images/train
      ann_path: /data/datasets/instruction_tuning/LLaVA/conversation_58k.json